---
title: "Maximize Meal Prep Efficiency Using Coding and AI"
seoTitle: "Optimize Meal Prep with AI and Coding"
seoDescription: "Enhance meal prep using coding and AI by automating recipe extraction from Instagram with open-source solutions for efficient and enjoyable planning"
datePublished: Sun Jan 26 2025 23:00:32 GMT+0000 (Coordinated Universal Time)
cuid: cm6e83ix6000009l15mrf4ij1
slug: maximize-meal-prep-efficiency-using-coding-and-ai
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1737722749495/733f8900-2f50-4310-8b1e-1bad9e326635.jpeg
tags: ai, scraping, mealprepp

---

As a preface, I am a big fan of self-hosted and open-source software, I try to use as much of it to manage various digital parts of my life. Trying to find a way to better organize my meals I came across [Grocy](https://grocy.info/), a web-based self-hosted groceries & household management solution for your home. After two weeks of heavy use, there is nothing better for planning and managing meals especially when it comes to preparing my meals for a week ahead.

## The Issues with the Basics

After some time, searching up “meal prep recipes” stops yielding meaningful or novel results and one gets stuck on websites with recipes that you dont really want. What if there were a recommendation algorithm for food? Although not meant for food, [Instagram](https://www.instagram.com/) is a very big knowledge base of recipes + visuals and instructions for food you might really like.

As I started making recipes from Instagram, I couldnt help but find the process very inefficient and bothersome - having to keep a post open and read chaotic captions. One evening I had finally decided to solve this issue as it had been bothering me for a while and the solution just seems so simple.

## Solution

I quickly got to opening Emacs and starting a new project. First steps: i) Function that can extract the description from an instagram post. ii) Structure data from description into defined format. With a little help from [ChatGPT](https://chatgpt.com/) and [GitHub Copilot](https://github.com/features/copilot) I was able to get these two down within about 20 minutes. And was then able to move on the a more high level approach to serving this app in a minimal and yet viable way.

### Instagram Descriptions Extraction

The first safe bet for getting data from websites is selenium, which for this project has just the right amount of complexity, however in my search I did come across [SeleniumBase](https://seleniumbase.io/) which is actually capable of extracting much more information from website that other tools just cannot get to. Since the web is a very structured place, extracting the description was quite simple:

```python
driver = webdriver.Chrome(options=options)
try:
    driver.get(url)
    time.sleep(5)  # Wait for page to load

    # Instagram caption is often in the og:description meta tag
    try:
        description = driver.find_element(
            By.XPATH, "//meta[@property='og:description']"
        ).get_attribute("content")
    except Exception as e:
        print("Error fetching description:", e)
        description = ""
finally:
    driver.quit()
```

And we now have our description given literally any instagram post form a public page.

### Parsing Data into Structure

Once we have our description from the above function, we can then use a simple snippet form the OpenAI documentation which takes care of extracting any text data into a defined pydantic model. Our model is very simple:

```python
class Ingredient(BaseModel):
    name: str
    quantity: float
    unit: str
    optional: bool

class RecipeSchema(BaseModel):
    name: str
    ingredients: List[Ingredient]
    instructions: List[str]
```

To make this a bit more efficient, I wrote some custom decorators which will cache our extraction and formatting functions so we do not over-send any requests and save on our OpenAI calls. Alternatively one could also use locally hosted LLMs or perhaps some regex parsing since this is a very simple case, but for the sake of my time I chose the easy solution.

### Packaging

Once we have our core functionality I chose to create a flask wrapper which hosts our features in a minimal UI where anyone can submit a URL and view the recipes created and stored in an sqlite database. One reason why I did not go for streamlit which would be much easier in terms of development, is that I wanted to make this as interoperable as I could, so anyone could fetch the recipe with just a simple `?format=json` flag at the recipe URL.

Once the app was up and running I span up a web app an [pythonanywhere](https://www.pythonanywhere.com/) and could instantly get structured recipes from anywhere in the world. This is a very naive implementation as it was done very quickly and just as a tool for anyone to use when they need.

In conclusion, leveraging technology like Grocy, Instagram, and AI tools can significantly enhance the meal prepping process, making it more efficient and enjoyable. By automating the extraction and structuring of recipe data from Instagram, you can save time and effort, allowing for a more streamlined approach to meal planning. The integration of open-source software and AI not only simplifies the task but also offers a customizable and scalable solution for anyone looking to optimize their meal preparation routine. This innovative approach demonstrates the potential of combining technology with everyday tasks to improve productivity and convenience. You can find the website here: [https://velocitatem.pythonanywhere.com/](https://velocitatem.pythonanywhere.com/) or on my [GitHub](https://github.com/velocitatem/chefbyte).